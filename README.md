# ðŸ§  Failure-Aware Generative AI System

## 1. Problem Statement

Modern generative AI systems often produce fluent outputs that may be:

- Ungrounded  
- Hallucinated  
- Internally inconsistent  
- Overconfident  

This project implements a **failure-aware generative inference system** designed to:

1. Detect unreliable model outputs  
2. Quantify uncertainty via structured signals  
3. Route high-risk responses to human review  
4. Support document-based and general question answering  

The system prioritizes **controlled deployment of generative models**, not unrestricted chatbot behavior.

---

## 2. System Capabilities

- Local LLM inference (Ollama-based)
- Retrieval-Augmented Generation (RAG)
- PDF ingestion
- OCR ingestion (image-based text extraction)
- Embedding-based semantic grounding validation
- Multi-generation stability detection
- Self-critique evaluation
- Composite confidence scoring
- Structured failure logging
- Human review routing
- FastAPI production backend
- Streamlit thin client interface

---

## 3. High-Level Architecture

```text
User Query
    â†“
FastAPI Service Layer
    â†“
Inference Service
    â†“
LLM Generation (Multiple Runs)
    â†“
Uncertainty Layer
    â€¢ Stability Analysis
    â€¢ Grounding Similarity
    â€¢ Self-Critique Validation
    â†“
Composite Confidence Score
    â†“
Failure Detector
    â†“
Router
    â€¢ Auto Accept
    â€¢ Human Review
```

---

## 4. Project Structure

```text
core/
â”œâ”€â”€ stability_engine.py
â”œâ”€â”€ failure_detector.py
â”œâ”€â”€ failure_reasoner.py
â”œâ”€â”€ router.py
â””â”€â”€ logger.py

domains/genai/
â”œâ”€â”€ llm_model.py
â”œâ”€â”€ embedding_model.py
â”œâ”€â”€ retriever.py
â”œâ”€â”€ grounding.py
â”œâ”€â”€ self_critique.py
â””â”€â”€ prompt_builder.py

ingestion/
â”œâ”€â”€ pdf_loader.py
â”œâ”€â”€ image_loader.py
â””â”€â”€ text_splitter.py

api/
â”œâ”€â”€ main.py
â”œâ”€â”€ routers/
â”œâ”€â”€ services/
â””â”€â”€ schemas/

ui/
â””â”€â”€ streamlit_app.py

config/
â””â”€â”€ genai_rag.yaml

human_review/
â””â”€â”€ queue/
```

---

## 5. Uncertainty Modeling Strategy

This system does **not** rely on token-level probabilities (which are often unavailable in local LLM deployments).

Instead, it computes uncertainty using structured signals:

### 5.1 Multi-Generation Stability

The same prompt is generated multiple times.

If outputs diverge:
- `stable = False`
- Confidence decreases

---

### 5.2 Semantic Grounding Similarity

Cosine similarity is computed between:

- Generated answer embedding  
- Retrieved document embeddings  

Low similarity â†’ weak grounding signal.

---

### 5.3 Self-Critique Evaluation

The model is prompted to evaluate its own output.

If critique returns:

```
UNSAFE
```

The output is flagged for escalation.

---

## 6. Composite Confidence Model

```text
Confidence =
    0.3 Ã— Grounding Similarity
  + 0.4 Ã— Stability
  + 0.3 Ã— Self-Critique Pass
```

Routing threshold:

```text
If Confidence < 0.45 â†’ escalate to human review
```

> Note:  
> This is a heuristic composite model, not a calibrated probabilistic confidence estimator.

---

## 7. Routing Logic

Outputs are routed based on:

- Low composite confidence  
- Explicit critique failure  
- Structured failure signals  

Possible decisions:

- `auto_accept`
- `human_review`

Escalated cases are stored in:

```text
human_review/queue/
```

---

## 8. Document Ingestion Pipeline

Supported formats:

- PDF  
- PNG / JPG (OCR-based extraction)

Processing pipeline:

```text
Document
    â†“
Text Extraction
    â†“
Chunking
    â†“
Embedding
    â†“
Vector Retrieval
    â†“
RAG Context Injection
```

If no document is provided, the system operates in hybrid general Q&A mode.

---

## 9. API Layer

FastAPI exposes:

```http
POST /ask
```

### Request

```json
{
  "question": "What is a qubit?",
  "document_path": null
}
```

### Response

```json
{
  "answer": "...",
  "confidence_score": 0.92,
  "grounding_similarity": 0.81,
  "stable": true,
  "failures": [],
  "decision": "auto_accept"
}
```

Swagger UI available at:

```
http://127.0.0.1:8000/docs
```

---

## 10. Running The System

### Start API

```bash
uvicorn api.main:app --reload
```

### Start UI

```bash
streamlit run ui/streamlit_app.py
```

---

## 11. Design Principles

This project emphasizes:

- Failure detection over blind generation  
- Explicit uncertainty modeling  
- Service-layer separation  
- Modular architecture  
- Deployment-oriented structure  

It is not optimized for:

- Maximum creative generation  
- Ultra-low latency  
- Fully calibrated probabilistic uncertainty  

---

## 12. Limitations

- Confidence model is heuristic-based  
- No entropy-based uncertainty modeling yet  
- No distributed scaling layer  
- No containerization (planned)  

---

## 13. Future Work

- Risk-based uncertainty scoring  
- Entropy-based generation disagreement metrics  
- Model versioning  
- CI/CD pipeline  
- Docker containerization  
- Observability (metrics + monitoring dashboards)  

---

## 14. Positioning

This project demonstrates:

- Applied ML system architecture  
- Generative AI orchestration  
- Uncertainty-aware deployment logic  
- Backend service engineering  
- Failure-aware routing strategy  

It serves as a bridge between:

- Applied ML Engineering  
- MLOps Foundations  
- Reliable Generative AI Infrastructure  